from __future__ import annotations

import logging
from dataclasses import dataclass
from typing import Any, Callable

import random
from time import perf_counter

from recommendations.filters import apply_author_instance_caps
from recommendations.sources import SimilarFromLikesSource


@dataclass(frozen=True)
class ExploitFromLikesDeps:
    source: SimilarFromLikesSource
    fallback_source: SimilarFromLikesSource | None
    fetch_recent_likes: Callable[[str, int], list[dict[str, Any]]]
    max_likes: int


class ExploitFromLikesGenerator:
    name = "exploit"

    def __init__(self, deps: ExploitFromLikesDeps) -> None:
        self.deps = deps

    def get_candidates(
        self,
        server: Any,
        user_id: str,
        limit: int,
        refresh_cache: bool = False,
        config: dict[str, Any] | None = None,
    ) -> list[dict[str, Any]]:
        if limit <= 0:
            return []
        config = config or {}
        exploit_min = float(config.get("exploit_min") or 0.0)
        pool_size = int(config.get("pool_size") or 0)
        max_per_instance = int(config.get("max_per_instance") or 0)
        max_per_author = int(config.get("max_per_author") or 0)
        pool_limit = max(pool_size, limit)

        likes = self.deps.fetch_recent_likes(user_id, self.deps.max_likes)

        if not likes:
            return []

        pool_start = perf_counter()
        rows = self.deps.source.get_candidates(server, user_id, pool_limit, refresh_cache)
        if not rows and self.deps.fallback_source is not None:
            logging.info(
                "[recommendations] exploit source fallback=%s",
                self.deps.fallback_source.name,
            )
            rows = self.deps.fallback_source.get_candidates(
                server, user_id, pool_limit, refresh_cache
            )
        if not rows:
            return []
        pool_ms = int((perf_counter() - pool_start) * 1000)

        rows, _, _, _ = apply_author_instance_caps(
            rows,
            max_per_author,
            max_per_instance,
        )
        if not rows:
            return []

        score_start = perf_counter()
        similarities = [_extract_similarity(row) for row in rows]
        pool_min = min(similarities) if similarities else None
        pool_max = max(similarities) if similarities else None
        logging.info(
            "[recommendations] exploit pool similarity min=%s max=%s pool=%d",
            f"{pool_min:.4f}" if pool_min is not None else "n/a",
            f"{pool_max:.4f}" if pool_max is not None else "n/a",
            len(rows),
        )
        filtered = [row for row in rows if _extract_similarity(row) >= exploit_min]
        in_range = len(filtered)
        if in_range > limit:
            filtered = random.sample(filtered, limit)
        else:
            filtered.sort(key=lambda item: _extract_similarity(item), reverse=True)
        score_ms = int((perf_counter() - score_start) * 1000)
        for entry in filtered:
            entry["debug_exploit_pool_size"] = len(rows)
            entry["debug_exploit_in_range"] = in_range
        logging.info(
            "[recommendations] exploit candidates in-range=%d pool=%d min=%.4f",
            len(filtered),
            len(rows),
            exploit_min,
        )
        total_ms = int((perf_counter() - pool_start) * 1000)
        logging.info(
            "[recommendations] exploit timing pool=%dms score=%dms total=%dms size=%d",
            pool_ms,
            score_ms,
            total_ms,
            len(rows),
        )
        return filtered[:limit]


def _extract_similarity(candidate: dict[str, Any]) -> float:
    raw = candidate.get("similarity_score")
    if raw is None:
        raw = candidate.get("score")
    try:
        value = float(raw)
    except (TypeError, ValueError):
        return 0.0
    return value if value > 0 else 0.0
